---
description: 
globs: **/tests/**/*.py
alwaysApply: false
---
# Testing Practices

This document outlines best practices for testing components of the PersonalAssistant project.

## Environment Setup

All tests must be run in the `services` conda environment:

```bash
conda activate services
```

## Test Frameworks

- Use **unittest** for tz_common tests
- Use **pytest** for agent tests (e.g., NotionAgent, JsonAgent)

## Test Configuration Files

Each sub-project may have its own test configuration:

- **NotionAgent**: Uses `pytest.ini` with `testpaths = tests`
- **Common**: Uses `pyproject.toml` with pytest configuration
- **JsonAgent**: May use pytest without specific configuration

## Test Isolation

Tests should be isolated from each other:

1. Each test should set up its own environment
2. Tests should not depend on each other's state
3. Use temporary files and directories when needed
4. Clean up any resources after tests complete

## Test structure - Define constants

Declare all constant values used in a test at the beginning of test class. Simple objects that remain immutable should also be declared once. Apply DRY principle - each value used more than once should be defined before any test cases.

* Example
```python
class TestBlockManager(unittest.TestCase):

	# Test data constants
	TEST_UUID_1 = "12345678-1234-1234-1234-123456789abc"
	TEST_UUID_2 = "87654321-4321-4321-4321-210987654321"
	TEST_TIMESTAMP = "2023-01-01T00:00:00Z"
	
	# Common field values
	COMMON_FIELDS = {
		"content": "test content",
		"last_edited_time": TEST_TIMESTAMP,
		"created_time": TEST_TIMESTAMP,
		"icon": "some-icon",
		"bold": True,
		"request_id": "req-123",
		"url": "https://example.com"
	}
```

## Avoid Testing Trivial Imports

Skip testing imports that only verify module loading without any actual functionality. Focus testing efforts on:

- Business logic and algorithms
- Error handling and edge cases
- Integration between components
- Data validation and transformation

## Test-Suite lifecycle and maintenance

### Keep the Suite Relevant

* Routinely prune empty, placeholder, or obsolete tests.
* Add new tests only for current, meaningful API behaviour.

 ### Know the Test's Purpose

* **Migration / Verification tests** - temporary helpers to confirm parity with a legacy system. Plan their deletion as soon as the migration is finished.
* **Unit tests** - isolate and check one small unit of logic.
* **Integration tests** - exercise interactions across components.

 ## Ask the Value Question First

* Before writing any test, ask: “Will this still earn its keep after the feature ships?”
* If its value disappears (e.g., after a migration), schedule its removal up front.

 ### Organise by Production Module

* Prefer one test file per production file (e.g., `block_manager.py` → `test_block_manager.py`).
* When a file grows, group related cases into classes within the same file (`TestCache`, `TestFiltering`, …).
* Split into a separate file only when the new scope is clearly distinct and enduring.

 ### Avoid “Phase” Files

* Do not create throw-away files like `test_feature_phase1.py`, `test_feature_phase2.py`.
* Append new scenarios to the existing file instead of scattering tests across versions.

Follow these principles yo keeps the test suite clear, lean, and genuinely protective of the evolving codebase.




