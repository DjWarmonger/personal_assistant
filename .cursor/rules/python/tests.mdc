---
description: 
globs: **/tests/**/*.py
alwaysApply: false
---
# Testing Practices

This document outlines best practices for testing components of the PersonalAssistant project.

## Environment Setup

All tests must be run in the `services` conda environment:

```bash
conda activate services
```

## Test Frameworks

- Use **unittest** for tz_common tests
- Use **pytest** for agent tests (e.g., NotionAgent, JsonAgent)

## Running Tests from Root Directory

Always run tests from the project root directory (`PersonalAssistant`). Use `cwd` if you encounter any issue with testing directories.

Here are example commands for each sub-project:

### Common Library (tz_common)
```bash
# Run all tests
conda activate services
python -m unittest discover -s common/tests

# Run specific test file
python -m unittest common.tests.test_imports
```

### Agents
```bash
# Run all tests for NotionAgent
conda activate services
python -m pytest Agents/NotionAgent/tests

# Run with verbose output for NotionAgent
python -m pytest Agents/NotionAgent/tests -v

# Run specific test file for JsonAgent
python -m pytest Agents/JsonAgent/tests/test_specific_file.py

# Run specific test method for NotionAgent
python -m pytest Agents/NotionAgent/tests/test_block_cache.py::TestBlockCache::test_specific_method

# Run all tests with output capture disabled (useful for debugging)
conda activate services
python -m pytest -s Agents/JsonAgent/tests
```

## Test Configuration Files

Each sub-project may have its own test configuration:

- **NotionAgent**: Uses `pytest.ini` with `testpaths = tests`
- **Common**: Uses `pyproject.toml` with pytest configuration
- **JsonAgent**: May use pytest without specific configuration

## Running All Tests

To run tests for multiple sub-projects in sequence:

```bash
conda activate services

# Run common tests
echo "Running common tests..."
python -m unittest discover -s common/tests

# Run NotionAgent tests
echo "Running NotionAgent tests..."
python -m pytest Agents/NotionAgent/tests

# Run JsonAgent tests
echo "Running JsonAgent tests..."
python -m pytest Agents/JsonAgent/tests
```

## Test Isolation

Tests should be isolated from each other:

1. Each test should set up its own environment
2. Tests should not depend on each other's state
3. Use temporary files and directories when needed
4. Clean up any resources after tests complete

## Debugging Tests

For debugging failing tests:

```bash
# Run with verbose output and stop on first failure
python -m pytest Agents/NotionAgent/tests -v -x

# Run with pdb debugger on failures
python -m pytest Agents/NotionAgent/tests --pdb

# Run specific test with output capture disabled
python -m pytest -s Agents/NotionAgent/tests/test_file.py::test_method
```

# Remove empty / outdated tests - Case study

## Issue: Obsolete/Placeholder Tests in `test_block_tree.py`
*   The file `test_block_tree.py` contained many placeholder tests with `@patch` decorators but no actual assertions relevant to the current `BlockTree` API.

## Resolution: Obsolete/Placeholder Tests in `test_block_tree.py`
*   These tests were removed, and new, relevant tests were added for `is_empty`, `get_tree_str` on an empty tree, duplicate relationships, and `from_dict` with empty inputs.

## Prevention: Obsolete/Placeholder Tests in `test_block_tree.py`
*   Regularly review and clean up test suites to remove obsolete tests that no longer reflect the current codebase, improving clarity and maintainability.

## Avoid Testing Trivial Imports

Skip testing imports that only verify module loading without any actual functionality. Focus testing efforts on:

- Business logic and algorithms
- Error handling and edge cases
- Integration between components
- Data validation and transformation


