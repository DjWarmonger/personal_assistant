# Project overview

TZ Common is a library of utils, serving as  apart of TZ Framework for Autonomous Agents.

# Project Goals

The goals of utils is to streamline AI agent development, by providing a set of tools and utilities that are easy to use and understand. In particular:

* Provide ready solutions for common problems, that just work out of the box.

* Reduce code cuplication

* Minimize cognitive load. User should not need to guess or assume anything in order to use the tool.

* Tools should have little mutual dependencies and not enforce any particular architecture.

Common utils do not cover GUI, which is done is a separate subproject.

## TODO: Separate tools into different packages, especially:

* Data structures and ontologies

* LangChain wrappers

* Data converters

* Indexes and storage

# Architecture and methodologies

Each of the utils is supposed to be self-contained tool that can be simply used for a given purpose. Ease of use and understanding is the main focus, while generalizability is secondary.

* Using multiple layers of abstraction is not encouraged.

* User shoudl be able to use the tool without understanding its internals.

* As many implementation details as possible should be hidden from the user.

* Tools shoudl be stateless and not assume any prior steps or configuration done on the user side.

* Tools should be pre-configured with deault parameters and work out-of-the box.

## Concurrency

Slow LLM calls are handled in separate threads. It is required to hide any concurrency, especially async calls, from the user.

It is also required to always match id of the asyncronous call with the result.

## Dockerization

TZ Common is designed to be used in Docker containers. It is required to have a simple way to configure and run the library in any project.

### TODO: Build and deploy all the agents at once.

# Used libraries

Basic Python libraries are used wherever possible.

## Langchain / LangGraph

Most popular framework that handles LLM calls, chains and tool handling. TZ framework wraps it up with custom logic to sim0plify usage and cover unneccessary configuration options and unused layers of abstraction.

## Langfuse

For monitoring token usage and tracing LLM calls.

Langfuse should take no effort to configure, ideally it should just take  asingle line to set it up for the entire project.

## Graph databases

The core assumption is to be able to store knowledge in plain text and human-readable format, and to be able to manually edit and fix knowledge.

### LightRAG

Simple to use RAG library allowing to easily create and query graph databases. It is required to store complex dependencies in the knowledge base(s) used by agents.

LightRAG is wrapped in custom layer

### Neo4j

Industry standard, mainly used for visualizing knowledge graph and future compatibility with any other database or deployment tools.

# Library Contents

## Context data representation

It is important to unify handling of context, knowledge and tasks for all agents. It is also required to be able to track particular call, execution or session and point exact call, log or execution that was a source of a particular context.

* Store uuid for every context item, data source or generated artifact.

### TODO: Document class

Document is a basic structure that can represent any source data, text or multimedia, web url, but also text or other artifact generated by model.

It is required to be able to trace back to the source of particular knowledge, or statement in agent context.

### AgentTask

It is required to be able to associate executed task with its input context and output documents.

## AI Toolbox

Ready set of tools with well-defined purpose, such as basic LLM calls. AI-powered image generation or captioning.



